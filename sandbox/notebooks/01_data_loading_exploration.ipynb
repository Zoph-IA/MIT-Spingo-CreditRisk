{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# 01_data_loading_exploration.ipynb\n",
    "# Sandbox: Data Loading & Initial Exploration\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /home/eubgo/anaconda3/envs/ML/lib/python3.12/site-packages (2.0.1)\n",
      "Requirement already satisfied: pandas in /home/eubgo/anaconda3/envs/ML/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/eubgo/anaconda3/envs/ML/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/eubgo/anaconda3/envs/ML/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/eubgo/anaconda3/envs/ML/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/eubgo/anaconda3/envs/ML/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/eubgo/anaconda3/envs/ML/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xlrd pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/bronze/HubSpot CRM All Contacts Feb 27 2025.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading dataset: [Errno 2] No such file or directory: '../data/bronze/HubSpot CRM All Contacts Feb 27 2025.xls'\n"
     ]
    }
   ],
   "source": [
    "view_head = False\n",
    "try:\n",
    "    df = pd.read_excel(DATA_PATH)\n",
    "    n_cols = df.shape\n",
    "    n_rows = df.shape[0]\n",
    "    print(\"Dataset loaded successfully with {} rows and {} columns.\".format(n_rows, n_cols[1]))\n",
    "    view_head = True\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m cols = \u001b[38;5;28mlist\u001b[39m(\u001b[43mdf\u001b[49m.columns)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCOLUMNS FOR DATASET\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--------------------\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "print(\"COLUMNS FOR DATASET\")\n",
    "print(\"--------------------\")\n",
    "for col in cols:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_columns = [\n",
    "    # Personally identifiable information\n",
    "    'First Name', 'Last Name', '¿Cuál es tu nombre completo?', 'Apellido paterno',\n",
    "    'Email Domain', 'Phone number', 'Phone Number', 'Mobile Phone Number',\n",
    "    'Date of birth', 'Contraseña',\n",
    "    \n",
    "    # Postal codes\n",
    "    'Código Postal', 'Postal Code',\n",
    "    \n",
    "    # IP data (can be traceable)\n",
    "    'IP City', 'IP State/Region', 'IP Country', 'IP Timezone', 'IP Country Code', 'IP State Code/Region Code',\n",
    "    \n",
    "    # Personal documents\n",
    "    'Documento Identificacion Frente', 'Documento Identificacion Reverso',\n",
    "    'INE Anverso', 'INE Reverso', 'ine_pasaporte',\n",
    "    'Comprobante Domicilio Anverso', 'Comprobante Domicilio Reverso',\n",
    "    'Factura Original Anverso', 'Factura Original Reverso',\n",
    "    \n",
    "    # Personal marketing identifiers\n",
    "    'Google ad click id', 'Facebook click id',\n",
    "    \n",
    "    # Other personal identifiers\n",
    "    'Member email', 'Email of the agent that of the agent involved in the last WhatsApp conversation synced',\n",
    "    'Email of the agent that of the agent involved in the last WhatsApp message sent from the HubSpot UI',\n",
    "    'Domain to which registration email was sent', 'Inbox URL', 'LinkedIn URL'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sanitized = df.drop(columns=sensitive_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if view_head:\n",
    "    display(df_sanitized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns where all values are null\n",
    "null_columns = df_sanitized.columns[df_sanitized.isna().all()].tolist()\n",
    "\n",
    "print(f\"Number of columns with all values as NaN: {len(null_columns)}\")\n",
    "print(f\"Columns with all values as NaN:\")\n",
    "for col in null_columns:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "# Drop all columns with all null values\n",
    "df_sanitized_clean = df_sanitized.drop(columns=null_columns)\n",
    "\n",
    "# Print the shape before and after dropping\n",
    "print(f\"\\nDataFrame shape before dropping null columns: {df_sanitized.shape}\")\n",
    "print(f\"DataFrame shape after dropping null columns: {df_sanitized_clean.shape}\")\n",
    "print(f\"Number of columns removed: {df_sanitized.shape[1] - df_sanitized_clean.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify columns with more than 50% missing values\n",
    "high_null_cols = df_sanitized_clean.columns[df_sanitized_clean.isna().mean() > 0.5].tolist()\n",
    "print(f\"Columns with more than 50% null values: {len(high_null_cols)}\")\n",
    "for col in high_null_cols:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create a cleaned DataFrame by dropping those columns\n",
    "df_refined = df_sanitized_clean.drop(columns=high_null_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Show original and final shape\n",
    "print(f\"\\nOriginal shape: {df_sanitized_clean.shape}\")\n",
    "print(f\"Shape after dropping high-null columns: {df_refined.shape}\")\n",
    "print(f\"Number of columns removed: {df_sanitized_clean.shape[1] - df_refined.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Display null percentage in remaining columns (top 10)\n",
    "remaining_null_pct = df_refined.isna().mean().sort_values(ascending=False) * 100\n",
    "print(\"\\nNull percentage in remaining columns (top 10):\")\n",
    "print(remaining_null_pct.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubspot_marketing_columns = [\n",
    "    'Record ID',\n",
    "    'Average Pageviews',\n",
    "    'Contact owner',\n",
    "    'Contact unworked',\n",
    "    'Create Date',\n",
    "    'Cumulative time in \"Lead (Lifecycle Stage Pipeline)\" (HH:mm:ss)',\n",
    "    'Currently in workflow',\n",
    "    'Date entered \"Lead (Lifecycle Stage Pipeline)\"',\n",
    "    'Date entered \"Marketing Qualified Lead (Lifecycle Stage Pipeline)\"',\n",
    "    'Date exited \"Lead (Lifecycle Stage Pipeline)\"',\n",
    "    'Date of first engagement',\n",
    "    'Description of first engagement',\n",
    "    'Event Revenue',\n",
    "    'First Conversion',\n",
    "    'First Conversion Date',\n",
    "    'First marketing email open date',\n",
    "    'First marketing email send date',\n",
    "    'First Page Seen',\n",
    "    'First Referring Site',\n",
    "    'HubSpot Team',\n",
    "    'ID of first engagement',\n",
    "    'Last Activity Date',\n",
    "    'Last Contacted',\n",
    "    'Last marketing email name',\n",
    "    'Last marketing email open date',\n",
    "    'Last marketing email send date',\n",
    "    'Last Modified Date',\n",
    "    'Last Page Seen',\n",
    "    'Last Referring Site',\n",
    "    'Last Touch Converting Campaign',\n",
    "    'Latest time in \"Lead (Lifecycle Stage Pipeline)\" (HH:mm:ss)',\n",
    "    'Latest Traffic Source',\n",
    "    'Latest Traffic Source Date',\n",
    "    'Latest Traffic Source Drill-Down 1',\n",
    "    'Latest Traffic Source Drill-Down 2',\n",
    "    'Lead response time (HH:mm:ss)',\n",
    "    'Lead Status',\n",
    "    'Lifecycle Stage',\n",
    "    'Marketing contact status',\n",
    "    'Marketing contact until next update',\n",
    "    'Marketing emails delivered',\n",
    "    'Marketing emails opened',\n",
    "    'Number of event completions',\n",
    "    'Number of Form Submissions',\n",
    "    'Number of Pageviews',\n",
    "    'Number of Sales Activities',\n",
    "    'Number of Sessions',\n",
    "    'Number of times contacted',\n",
    "    'Number of Unique Forms Submitted',\n",
    "    'Original Traffic Source',\n",
    "    'Original Traffic Source Drill-Down 1',\n",
    "    'Original Traffic Source Drill-Down 2',\n",
    "    'Owner assigned date',\n",
    "    'Recent Conversion',\n",
    "    'Recent Conversion Date',\n",
    "    'Record source'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop hubspot_marketing_columns\n",
    "df_refined = df_refined.drop(columns=hubspot_marketing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = df_refined.isna().mean().sort_values(ascending=False) * 100\n",
    "print(\"\\nNull percentage in remaining column\")\n",
    "print(null_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_unique_values(df, max_unique=20, max_examples=5):\n",
    "    results = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Get non-null values\n",
    "        non_null_values = df[col].dropna()\n",
    "        \n",
    "        # Calculate number of unique values\n",
    "        n_unique = df[col].nunique()\n",
    "        \n",
    "        # Get counts of unique values\n",
    "        value_counts = df[col].value_counts(dropna=False)\n",
    "        \n",
    "        # Determine data type\n",
    "        dtype = df[col].dtype\n",
    "        \n",
    "        # Prepare examples of values\n",
    "        if n_unique <= max_unique:\n",
    "            # If there are few unique values, show all with their counts\n",
    "            examples = value_counts.to_dict()\n",
    "        else:\n",
    "            # If there are many unique values, show only the first examples\n",
    "            examples = non_null_values.head(max_examples).tolist()\n",
    "        \n",
    "        # Add information to results\n",
    "        results.append({\n",
    "            'Column': col,\n",
    "            'Type': dtype,\n",
    "            'Unique_Values': n_unique,\n",
    "            'Nulls_%': null_percentage[col],\n",
    "            'Examples': examples\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary of unique values for each column\n",
    "unique_values_summary = show_unique_values(df_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== SUMMARY OF UNIQUE VALUES BY COLUMN =====\")\n",
    "for i, row in unique_values_summary.iterrows():\n",
    "    print(f\"\\n{i+1}. {row['Column']} ({row['Type']})\")\n",
    "    print(f\"   - Unique values: {row['Unique_Values']}\")\n",
    "    print(f\"   - Nulls: {row['Nulls_%']:.2f}%\")\n",
    "    \n",
    "    # Show examples of values\n",
    "    print(\"   - Examples:\")\n",
    "    if isinstance(row['Examples'], dict):\n",
    "        # If we have a dictionary of counts, show value: count\n",
    "        for val, count in row['Examples'].items():\n",
    "            if pd.isna(val):\n",
    "                print(f\"     * NaN: {count}\")\n",
    "            else:\n",
    "                print(f\"     * {val}: {count}\")\n",
    "    else:\n",
    "        # If we have a list of examples\n",
    "        for val in row['Examples']:\n",
    "            print(f\"     * {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
